{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kXwwFZIJD-MF"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.parameter import Parameter\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import operator\n",
        "from functools import reduce\n",
        "from functools import partial\n",
        "from timeit import default_timer\n",
        "\n",
        "torch.manual_seed(0)\n",
        "np.random.seed(0)\n",
        "\n",
        "\n",
        "#  1d fourier layer\n",
        "\n",
        "class SpectralConv1d(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, modes1):\n",
        "        super(SpectralConv1d, self).__init__()\n",
        "\n",
        "        \"\"\"\n",
        "        1D Fourier layer. It does FFT, linear transform, and Inverse FFT.    \n",
        "        \"\"\"\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.modes1 = modes1  #Number of Fourier modes to multiply, at most floor(N/2) + 1\n",
        "\n",
        "        self.scale = (1 / (in_channels*out_channels))\n",
        "        self.weights1 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, dtype=torch.cfloat))\n",
        "\n",
        "    # Complex multiplication\n",
        "    def compl_mul1d(self, input, weights):\n",
        "        # (batch, in_channel, x ), (in_channel, out_channel, x) -> (batch, out_channel, x)\n",
        "        return torch.einsum(\"bix,iox->box\", input, weights)\n",
        "\n",
        "    def forward(self, x, out_ft0 = None):\n",
        "        batchsize = x.shape[0]\n",
        "        #Compute Fourier coeffcients up to factor of e^(- something constant)\n",
        "        x_ft = torch.fft.rfft(x)\n",
        "\n",
        "        # Multiply relevant Fourier modes\n",
        "        out_ft = torch.zeros(batchsize, self.out_channels, x.size(-1)//2 + 1,  device=x.device, dtype=torch.cfloat)\n",
        "        out_ft[:, :, :self.modes1] = self.compl_mul1d(x_ft[:, :, :self.modes1], self.weights1)\n",
        "        if out_ft0 is not None:\n",
        "          out_ft0 += out_ft\n",
        "        else:\n",
        "          out_ft0 = out_ft\n",
        "\n",
        "        #Return to physical space\n",
        "        x = torch.fft.irfft(out_ft0, n=x.size(-1))\n",
        "        return x, out_ft\n",
        "\n",
        "class FNO1d(nn.Module):\n",
        "    def __init__(self, modes, width):\n",
        "        super(FNO1d, self).__init__()\n",
        "\n",
        "        \"\"\"\n",
        "        The overall network. It contains 4 layers of the Fourier layer.\n",
        "        1. Lift the input to the desire channel dimension by self.fc0 .\n",
        "        2. 4 layers of the integral operators u' = (W + K)(u).\n",
        "            W defined by self.w; K defined by self.conv .\n",
        "        3. Project from the channel space to the output space by self.fc1 and self.fc2 .\n",
        "        \n",
        "        input: the solution of the initial condition and location (a(x), x)\n",
        "        input shape: (batchsize, x=s, c=2)\n",
        "        output: the solution of a later timestep\n",
        "        output shape: (batchsize, x=s, c=1)\n",
        "        \"\"\"\n",
        "\n",
        "        self.modes1 = modes\n",
        "        self.width = width\n",
        "        self.fc0 = nn.Linear(1, self.width) # input channel is 2: (a(x), x)\n",
        "\n",
        "        self.conv0 = SpectralConv1d(self.width, self.width, self.modes1)\n",
        "        self.conv1 = SpectralConv1d(self.width, self.width, self.modes1)\n",
        "        self.conv2 = SpectralConv1d(self.width, self.width, self.modes1)\n",
        "        self.conv3 = SpectralConv1d(self.width, self.width, self.modes1)\n",
        "        self.w0 = nn.Conv1d(self.width, self.width, 1)\n",
        "        self.w1 = nn.Conv1d(self.width, self.width, 1)\n",
        "        self.w2 = nn.Conv1d(self.width, self.width, 1)\n",
        "        self.w3 = nn.Conv1d(self.width, self.width, 1)\n",
        "\n",
        "\n",
        "        self.fc1 = nn.Linear(self.width, 128)\n",
        "        self.fc2 = nn.Linear(128, 1)\n",
        "\n",
        "    def forward(self, x,  out_ft0 = None, out_ft1 = None, out_ft2 = None, out_ft3 = None):\n",
        "\n",
        "        x = self.fc0(x)\n",
        "        x = x.permute(0, 2, 1)\n",
        "\n",
        "        if out_ft0 is None:\n",
        "\n",
        "          x1, out_ft0 = self.conv0(x)\n",
        "          x2 = self.w0(x)\n",
        "          x = x1 + x2\n",
        "          x = F.relu(x)\n",
        "        else:\n",
        "          x1, out_ft0 = self.conv0(x, out_ft0)\n",
        "          x2 = self.w0(x)\n",
        "          x = x1 + x2\n",
        "          x = F.relu(x)\n",
        "        \n",
        "       if out_ft1 is None:\n",
        "          x1, out_ft1 = self.conv1(x)\n",
        "          x2 = self.w1(x)\n",
        "          x = x1 + x2\n",
        "          x = F.relu(x)\n",
        "       else:\n",
        "          x1, out_ft1 = self.conv1(x, out_ft1)\n",
        "          x2 = self.w1(x)\n",
        "          x = x1 + x2\n",
        "          x = F.relu(x)\n",
        "        \n",
        "        if out_ft2 is None:\n",
        "          x1, out_ft2 = self.conv2(x)\n",
        "          x2 = self.w2(x)\n",
        "          x = x1 + x2\n",
        "          x = F.relu(x)\n",
        "        else:\n",
        "          x1, out_ft2 = self.conv2(x, out_ft2)\n",
        "          x2 = self.w2(x)\n",
        "          x = x1 + x2\n",
        "          x = F.relu(x)\n",
        "        \n",
        "        if out_ft3 is None:\n",
        "          x1, out_ft3 = self.conv3(x)\n",
        "          x2 = self.w3(x)\n",
        "          x = x1 + x2\n",
        "        else:\n",
        "          x1, out_ft3 = self.conv3(x, out_ft3)\n",
        "          x2 = self.w3(x)\n",
        "          x = x1 + x2\n",
        "          \n",
        "\n",
        "\n",
        "        x = x.permute(0, 2, 1)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x, out_ft0, out_ft1, out_ft2, out_ft3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Coupled Data\n",
        "ntrain = 1000\n",
        "ntest = 200\n",
        "\n",
        "sub = 2**0 #subsampling rate\n",
        "h = 2**8 // sub #total grid size divided by the subsampling rate\n",
        "s = h\n",
        "batch_size = 20\n",
        "\n",
        "rw_u = loadmat('/content/drive/MyDrive/gray_scott_results/Coupled_PDE_data/kernel1Drho_t0_1.mat')\n",
        "x_data = rw_u['rho_t0'].astype(np.float32)\n",
        "y_data = rw_u['rho_t02'].astype(np.float32)\n",
        "print(x_data.shape)\n",
        "\n",
        "x_train_u = x_data[:ntrain,::sub]\n",
        "y_train_u = y_data[:ntrain,::sub]\n",
        "x_test_u = x_data[-ntest:,::sub]\n",
        "y_test_u = y_data[-ntest:,::sub]\n",
        "\n",
        "x_train_u = torch.from_numpy(x_train_u)\n",
        "x_test_u = torch.from_numpy(x_test_u)\n",
        "y_train_u = torch.from_numpy(y_train_u)\n",
        "y_test_u = torch.from_numpy(y_test_u)\n",
        "\n",
        "x_train_u = x_train_u.unsqueeze(-1)\n",
        "x_test_u = x_test_u.unsqueeze(-1)\n",
        "\n",
        "rw_v = loadmat('/content/drive/MyDrive/gray_scott_results/Coupled_PDE_data/kernel1Dphi_t0_1.mat')\n",
        "x_data = rw_v['phi_t0'].astype(np.float32)\n",
        "y_data = rw_v['phi_t02'].astype(np.float32)\n",
        "\n",
        "x_train_v = x_data[:ntrain,::sub]\n",
        "y_train_v = y_data[:ntrain,::sub]\n",
        "x_test_v = x_data[-ntest:,::sub]\n",
        "y_test_v = y_data[-ntest:,::sub]\n",
        "\n",
        "x_train_v = torch.from_numpy(x_train_v)\n",
        "x_test_v = torch.from_numpy(x_test_v)\n",
        "y_train_v = torch.from_numpy(y_train_v)\n",
        "y_test_v = torch.from_numpy(y_test_v)\n",
        "print(y_test_u.shape)\n",
        "\n",
        "x_train_v = x_train_v.unsqueeze(-1)\n",
        "x_test_v = x_test_v.unsqueeze(-1)\n",
        "\n",
        "x_train = torch.cat([x_train_u.reshape(ntrain,s,1), x_train_v.reshape(ntrain,s,1)], dim=2)\n",
        "x_test = torch.cat([x_test_u.reshape(ntest,s,1), x_test_v.reshape(ntest,s,1)], dim=2)\n",
        "\n",
        "y_train = torch.cat([y_train_u.reshape(ntrain,s,1), y_train_v.reshape(ntrain,s,1)], dim=2)\n",
        "y_test = torch.cat([y_test_u.reshape(ntest,s,1), y_test_v.reshape(ntest,s,1)], dim=2)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(x_train, y_train), batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(x_test, y_test), batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1pyFw4ag5S_",
        "outputId": "9b33fc2d-7cd1-4731-8c1b-753325f2feab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "287361\n"
          ]
        }
      ],
      "source": [
        "# model\n",
        "learning_rate = 0.001\n",
        "\n",
        "epochs = 500\n",
        "step_size = 100\n",
        "gamma = 0.5\n",
        "\n",
        "modes = 16\n",
        "width = 64\n",
        "\n",
        "model1 = FNO1d(modes, width).cuda()\n",
        "model2 = FNO1d(modes, width).cuda()\n",
        "print(count_params(model1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Rb2s08zZVz7"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "optimizer1 = torch.optim.Adam(model1.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "scheduler1 = torch.optim.lr_scheduler.StepLR(optimizer1, step_size=step_size, gamma=gamma)\n",
        "\n",
        "optimizer2 = torch.optim.Adam(model2.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "scheduler2 = torch.optim.lr_scheduler.StepLR(optimizer2, step_size=step_size, gamma=gamma)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train and test\n",
        "error_u = []\n",
        "error_v = []\n",
        "mae_error_u = []\n",
        "mae_error_v = []\n",
        "\n",
        "\n",
        "# Train and test\n",
        "error_u = []\n",
        "error_v = []\n",
        "\n",
        "myloss = LpLoss(size_average=False)\n",
        "len_loader = ntrain/batch_size\n",
        "\n",
        "error = []\n",
        "\n",
        "for ep in range(epochs):\n",
        "    model1.train()\n",
        "    model2.train()\n",
        "    t1 = default_timer()\n",
        "    train_l2 = 0\n",
        "\n",
        "    train_l2_u = 0\n",
        "    train_l2_v = 0\n",
        "\n",
        "    flag_1 = 0\n",
        "    flag_2 = 0\n",
        "    for x, y in train_loader:\n",
        "        x, y = x.cuda(), y.cuda()\n",
        "\n",
        "        random_num = random.random()\n",
        "        if random_num < 0.5:\n",
        "            with torch.no_grad(): \n",
        "              out1, out_ft0, out_ft1, out_ft2, out_ft3 = model1(x[:,:,0].unsqueeze(-1))\n",
        "            optimizer2.zero_grad()\n",
        "\n",
        "            v_out_end, out_ft0, out_ft1, out_ft2, out_ft3 = model2(x[:,:,1].unsqueeze(-1), out_ft0= None, out_ft1=None, out_ft2=None, out_ft3=out_ft3)\n",
        "\n",
        "            l2_v = myloss(v_out_end.view(batch_size, -1), y[:,:,1].view(batch_size, -1))\n",
        "            l2_v.backward() # use the l2 relative loss\n",
        "\n",
        "            optimizer2.step()\n",
        "            train_l2_v += l2_v.item()\n",
        "\n",
        "            with torch.no_grad():\n",
        "               out2, out_ft0, out_ft1, out_ft2, out_ft3 = model2(x[:,:,1].unsqueeze(-1))\n",
        "\n",
        "            optimizer1.zero_grad()\n",
        "\n",
        "            u_out_end, out_ft0, out_ft1, out_ft2, out_ft3 = model1(x[:,:,0].unsqueeze(-1), out_ft0= None, out_ft1=None, out_ft2=None, out_ft3=out_ft3)\n",
        "            l2_u = myloss(u_out_end.view(batch_size, -1), y[:,:,0].view(batch_size, -1))\n",
        "            l2_u.backward() # use the l2 relative loss\n",
        "\n",
        "            optimizer1.step()\n",
        "            train_l2_u += l2_u.item()\n",
        "        else:\n",
        "\n",
        "            with torch.no_grad(): \n",
        "              out2, out_ft0, out_ft1, out_ft2, out_ft3 = model2(x[:,:,1].unsqueeze(-1))\n",
        "            optimizer1.zero_grad()\n",
        "\n",
        "            u_out_end, out_ft0, out_ft1, out_ft2, out_ft3 = model1(x[:,:,0].unsqueeze(-1), out_ft0= None, out_ft1=None, out_ft2=None, out_ft3=out_ft3)\n",
        "\n",
        "            l2_u = myloss(u_out_end.view(batch_size, -1), y[:,:,0].view(batch_size, -1))\n",
        "            l2_u.backward() # use the l2 relative loss\n",
        "\n",
        "            optimizer1.step()\n",
        "            train_l2_u += l2_u.item()\n",
        "\n",
        "            with torch.no_grad(): \n",
        "               out1, out_ft0, out_ft1, out_ft2, out_ft3 = model1(x[:,:,0].unsqueeze(-1))\n",
        "            optimizer2.zero_grad()\n",
        "\n",
        "            v_out_end, out_ft0, out_ft1, out_ft2, out_ft3 = model2(x[:,:,1].unsqueeze(-1), out_ft0= None, out_ft1=None, out_ft2=None, out_ft3=out_ft3)\n",
        "\n",
        "            l2_v = myloss(v_out_end.view(batch_size, -1), y[:,:,1].view(batch_size, -1))\n",
        "            l2_v.backward() # use the l2 re\n",
        "\n",
        "            optimizer2.step()\n",
        "            train_l2_v += l2_v.item()\n",
        "\n",
        "# # Test:\n",
        "    model1.eval()\n",
        "    model2.eval()\n",
        "\n",
        "    scheduler1.step()\n",
        "    scheduler2.step()\n",
        "\n",
        "    test_l2_u = 0.0\n",
        "    i = 0\n",
        "    for x, y in test_loader:\n",
        "        x, y = x.cuda(), y.cuda()\n",
        "        v_test_out_mid, out_ft0, out_ft1, out_ft2, out_ft3 = model2(x[:,:,1].unsqueeze(-1))\n",
        "        u_test_out_end, out_ft0, out_ft1, out_ft2, out_ft3 = model1(x[:,:,0].unsqueeze(-1), out_ft0= None, out_ft1=None, out_ft2=None, out_ft3=out_ft3)\n",
        "        u_test_out_end = u_test_out_end.view(batch_size, -1)\n",
        "        y = y[:,:,0].view(batch_size, -1)\n",
        "        if i == 0:\n",
        "            u_pred =  u_test_out_end\n",
        "            u_label = y\n",
        "            i += 1\n",
        "        else:\n",
        "            u_pred = torch.cat((u_pred, u_test_out_end),0)\n",
        "            u_label = torch.cat((u_label, y), 0)\n",
        "        \n",
        "        test_l2_u += myloss(u_test_out_end, y).item()\n",
        "\n",
        "    train_l2_u /= ntrain\n",
        "    test_l2_u /= ntest\n",
        "    error_u.append(test_l2_u)\n",
        "\n",
        "    test_l2_v = 0.0\n",
        "    i = 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in test_loader:\n",
        "            x, y = x.cuda(), y.cuda()\n",
        "            u_test_out_mid, out_ft0, out_ft1, out_ft2, out_ft3 = model1(x[:,:,0].unsqueeze(-1))\n",
        "            v_test_out_end, out_ft0, out_ft1, out_ft2, out_ft3 = model2(x[:,:,1].unsqueeze(-1), out_ft0= None, out_ft1=None, out_ft2=None, out_ft3=out_ft3)\n",
        "            v_test_out_end = v_test_out_end.view(batch_size, -1)\n",
        "            y = y[:,:,1].view(batch_size, -1)\n",
        "            if i == 0:\n",
        "                v_pred =  v_test_out_end\n",
        "                v_label = y\n",
        "                i += 1\n",
        "            else:\n",
        "                v_pred = torch.cat((v_pred, v_test_out_end),0)\n",
        "                v_label = torch.cat((v_label, y), 0)\n",
        "            test_l2_v += myloss(v_test_out_end, y).item()\n",
        "\n",
        "    train_l2_v /= ntrain\n",
        "    test_l2_v /= ntest\n",
        "    error_v.append(test_l2_v)\n",
        "\n",
        "    print(ep,train_l2_u, train_l2_v,test_l2_u, test_l2_v)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "00ee738ce916cf88a1092a185e07d03424f9fed6277c3e20762079d5b49ec728"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
